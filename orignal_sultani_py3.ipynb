{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "orignal sultani-py3.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dURmGkZc5Oda",
        "outputId": "fe0ad5c4-4221-48b5-8bc0-45945828d560"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall keras\n",
        "!pip install keras==1.1.0"
      ],
      "metadata": {
        "id": "demNCF4L8xcf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import theano\n",
        "import os\n",
        "os.environ[\"KERAS_BACKEND\"] = \"theano\"\n",
        "import keras.backend\n",
        "keras.backend.set_image_dim_ordering('th')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sLTVQ6pu05L2",
        "outputId": "5037256e-c21b-4108-9ddf-768c23461d85"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using Theano backend.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras import backend as K\n",
        "print(K.backend())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NSedwvwOxNg6",
        "outputId": "019c4283-aa5d-446a-f76d-e4dca280425b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "theano\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "keras.__version__"
      ],
      "metadata": {
        "id": "eTPIGFM993ix",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "c94c0700-fa8b-47c1-fac4-5afaf02a8cd7"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1.1.0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "theano.__version__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "YM59O4ZZxB7S",
        "outputId": "66a704ff-36f7-430b-cb34-8d0b60316421"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1.0.5'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "import tensorflow as tf\n",
        "from keras.layers import Dense, Dropout, Activation ,LSTM,Reshape\n",
        "from keras.regularizers import l2\n",
        "from keras.optimizers import SGD,adam, Adagrad\n",
        "from scipy.io import loadmat, savemat\n",
        "from keras.models import model_from_json\n",
        "import theano.tensor as T\n",
        "import theano\n",
        "import csv\n",
        "import collections\n",
        "import time\n",
        "import csv\n",
        "import os\n",
        "from os import listdir\n",
        "import skimage.transform\n",
        "from skimage import color\n",
        "from os.path import isfile, join\n",
        "import numpy as np\n",
        "import numpy\n",
        "from datetime import datetime\n",
        "from os.path import basename\n",
        "import glob"
      ],
      "metadata": {
        "id": "T3-xSL6lAd6y"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def custom_objective(y_true, y_pred):\n",
        "    'Custom Objective function'\n",
        "\n",
        "    y_true = T.flatten(y_true)\n",
        "    y_pred = T.flatten(y_pred)\n",
        "\n",
        "    print(y_true)\n",
        "    n_seg = 32  # Because we have 32 segments per video.\n",
        "    nvid = 4 # updated this to 4 ... it was some 60 \n",
        "    n_exp = nvid // 2 \n",
        "    Num_d=32*nvid\n",
        "\n",
        "    sub_max = T.ones_like(y_pred) # sub_max represents the highest scoring instants in bags (videos).\n",
        "    sub_sum_labels = T.ones_like(y_true) # It is used to sum the labels in order to distinguish between normal and abnormal videos.\n",
        "    sub_sum_l1=T.ones_like(y_true)  # For holding the concatenation of summation of scores in the bag.\n",
        "    sub_l2 = T.ones_like(y_true) # For holding the concatenation of L2 of score in the bag.\n",
        "\n",
        "    for ii in range(0, nvid, 1):\n",
        "        # For Labels\n",
        "        mm = y_true[ii * n_seg:ii * n_seg + n_seg]\n",
        "        sub_sum_labels = T.concatenate([sub_sum_labels, T.stack(T.sum(mm))])  # Just to keep track of abnormal and normal vidoes\n",
        "\n",
        "        # For Features scores\n",
        "        Feat_Score = y_pred[ii * n_seg:ii * n_seg + n_seg]\n",
        "        sub_max = T.concatenate([sub_max, T.stack(T.max(Feat_Score))])         # Keep the maximum score of scores of all instances in a Bag (video)\n",
        "        sub_sum_l1 = T.concatenate([sub_sum_l1, T.stack(T.sum(Feat_Score))])   # Keep the sum of scores of all instances in a Bag (video)\n",
        "\n",
        "        z1 = T.ones_like(Feat_Score)\n",
        "        z2 = T.concatenate([z1, Feat_Score])\n",
        "        z3 = T.concatenate([Feat_Score, z1])\n",
        "        z_22 = z2[31:]\n",
        "        z_44 = z3[:33]\n",
        "        z = z_22 - z_44\n",
        "        z = z[1:32]\n",
        "        z = T.sum(T.sqr(z))\n",
        "        sub_l2 = T.concatenate([sub_l2, T.stack(z)])\n",
        "\n",
        "\n",
        "    # sub_max[Num_d:] means include all elements after Num_d.\n",
        "    # AllLabels =[2 , 4, 3 ,9 ,6 ,12,7 ,18 ,9 ,14]\n",
        "    # z=x[4:]\n",
        "    #[  6.  12.   7.  18.   9.  14.]\n",
        "\n",
        "    sub_score = sub_max[Num_d:]  # We need this step since we have used T.ones_like\n",
        "    F_labels = sub_sum_labels[Num_d:] # We need this step since we have used T.ones_like\n",
        "    #  F_labels contains integer 32 for normal video and 0 for abnormal videos. This because of labeling done at the end of \"load_dataset_Train_batch\"\n",
        "\n",
        "\n",
        "    # AllLabels =[2 , 4, 3 ,9 ,6 ,12,7 ,18 ,9 ,14]\n",
        "    # z=x[:4]\n",
        "    # [ 2 4 3 9]... This shows 0 to 3 elements\n",
        "\n",
        "    print(n_exp)\n",
        "    sub_sum_l1 = sub_sum_l1[Num_d:] # We need this step since we have used T.ones_like\n",
        "    sub_sum_l1 = sub_sum_l1[:n_exp]\n",
        "    sub_l2 = sub_l2[Num_d:]         # We need this step since we have used T.ones_like\n",
        "    sub_l2 = sub_l2[:n_exp]\n",
        "\n",
        "\n",
        "    indx_nor = theano.tensor.eq(F_labels, 32).nonzero()[0]  # Index of normal videos: Since we labeled 1 for each of 32 segments of normal videos F_labels=32 for normal video\n",
        "    indx_abn = theano.tensor.eq(F_labels, 0).nonzero()[0]\n",
        "\n",
        "    n_Nor=n_exp\n",
        "\n",
        "    Sub_Nor = sub_score[indx_nor] # Maximum Score for each of abnormal video\n",
        "    Sub_Abn = sub_score[indx_abn] # Maximum Score for each of normal video\n",
        "\n",
        "    z = T.ones_like(y_true)\n",
        "    for ii in range(0, n_Nor, 1):\n",
        "        sub_z = T.maximum(1 - Sub_Abn + Sub_Nor[ii], 0)\n",
        "        z = T.concatenate([z, T.stack(T.sum(sub_z))])\n",
        "\n",
        "    z = z[Num_d:]  # We need this step since we have used T.ones_like\n",
        "    z = T.mean(z, axis=-1) +  0.00008*T.sum(sub_sum_l1) + 0.00008*T.sum(sub_l2)  # Final Loss f\n",
        "\n",
        "    print(\"hello\")\n",
        "    return z\n",
        "\n"
      ],
      "metadata": {
        "id": "iWJ-0F_EpXD8"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Create Model\")\n",
        "model = Sequential()\n",
        "model.add(Dense(512, input_dim=4096,init='glorot_normal',W_regularizer=l2(0.001),activation='relu'))\n",
        "# model.add(Dropout(0.6)) # some error .. ignornig it since we are not interested in the exact netwrk\n",
        "model.add(Dense(32,init='glorot_normal',W_regularizer=l2(0.001)))\n",
        "# model.add(Dropout(0.6))\n",
        "model.add(Dense(1,init='glorot_normal',W_regularizer=l2(0.001),activation='sigmoid'))\n",
        "adagrad=Adagrad(lr=0.01, epsilon=1e-08)\n",
        "model.compile(loss=custom_objective, optimizer=adagrad)\n",
        "\n",
        "print(\"Starting training...\")\n",
        "\n",
        "AllClassPath='/content/gdrive/MyDrive/data/train/'\n",
        "output_dir='/content/gdrive/MyDrive/data/'\n",
        "# Output_dir is the directory where you want to save trained weights\n",
        "weights_path = output_dir + 'weights.mat'\n",
        "# weights.mat are the model weights that you will get after (or during) that training\n",
        "model_path = output_dir + 'model.json'\n",
        "\n",
        "if not os.path.exists(output_dir):\n",
        "       os.makedirs(output_dir)\n",
        "\n",
        "All_class_files= listdir(AllClassPath)\n",
        "All_class_files.sort()\n",
        "loss_graph =[]\n",
        "num_iters = 20000\n",
        "total_iterations = 0\n",
        "batchsize=60\n",
        "time_before = datetime.now()\n",
        "\n",
        "for it_num in range(num_iters):\n",
        "\n",
        "    AbnormalPath = os.path.join(AllClassPath, All_class_files[0])  # Path of abnormal already computed C3D features\n",
        "    NormalPath = os.path.join(AllClassPath, All_class_files[1])    # Path of Normal already computed C3D features\n",
        "    inputs, targets=load_dataset_Train_batch(AbnormalPath, NormalPath)  # Load normal and abnormal video C3D features\n",
        "    batch_loss =model.train_on_batch(inputs, targets)\n",
        "    loss_graph = np.hstack((loss_graph, batch_loss))\n",
        "    total_iterations += 1\n",
        "    if total_iterations % 20 == 1:\n",
        "        print(\"These iteration=\" + str(total_iterations) + \") took: \" + str(datetime.now() - time_before) + \", with loss of \" + str(batch_loss))\n",
        "        iteration_path = output_dir + 'Iterations_graph_' + str(total_iterations) + '.mat'\n",
        "        savemat(iteration_path, dict(loss_graph=loss_graph))\n",
        "    if total_iterations % 1000 == 0:  # Save the model at every 1000th iterations.\n",
        "       weights_path = output_dir + 'weightsAnomalyL1L2_' + str(total_iterations) + '.mat'\n",
        "      #  save_model(model, model_path, weights_path)\n",
        "\n",
        "\n",
        "# save_model(model, model_path, weights_path)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 657
        },
        "id": "NOEjTsMPzm0F",
        "outputId": "f866af24-d441-4e74-c9d4-b4e7b0efeb08"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Create Model\n",
            "Reshape{1}.0\n",
            "2\n",
            "hello\n",
            "Starting training...\n",
            "Loading training batch\n",
            "Loading Abnormal videos Features...\n",
            " Abnormal Features  loaded\n",
            "(32, 4096)\n",
            "[0.00429  0.       0.010251 ... 0.       0.       0.021183]\n",
            "Loading Normal videos...\n",
            "Features  loaded\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-5660b2d860fe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0mNormalPath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAllClassPath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAll_class_files\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m    \u001b[0;31m# Path of Normal already computed C3D features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mload_dataset_Train_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAbnormalPath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNormalPath\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Load normal and abnormal video C3D features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m     \u001b[0mbatch_loss\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m     \u001b[0mloss_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0mtotal_iterations\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/models.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, class_weight, sample_weight, **kwargs)\u001b[0m\n\u001b[1;32m    710\u001b[0m         return self.model.train_on_batch(x, y,\n\u001b[1;32m    711\u001b[0m                                          \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 712\u001b[0;31m                                          class_weight=class_weight)\n\u001b[0m\u001b[1;32m    713\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    714\u001b[0m     def test_on_batch(self, x, y,\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1218\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1219\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1220\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1221\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1222\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_make_train_function\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    701\u001b[0m                                              \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal_loss\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics_tensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    702\u001b[0m                                              \u001b[0mupdates\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mupdates\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 703\u001b[0;31m                                              **self._function_kwargs)\n\u001b[0m\u001b[1;32m    704\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    705\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_test_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/backend/theano_backend.py\u001b[0m in \u001b[0;36mfunction\u001b[0;34m(inputs, outputs, updates, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m                 \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Invalid argument '%s' passed to K.function\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mFunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupdates\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mupdates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    729\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/backend/theano_backend.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, inputs, outputs, updates, **kwargs)\u001b[0m\n\u001b[1;32m    711\u001b[0m                                         \u001b[0mallow_input_downcast\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    712\u001b[0m                                         \u001b[0mon_unused_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ignore'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 713\u001b[0;31m                                         **kwargs)\n\u001b[0m\u001b[1;32m    714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    715\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/theano/compile/function/__init__.py\u001b[0m in \u001b[0;36mfunction\u001b[0;34m(inputs, outputs, mode, updates, givens, no_default_updates, accept_inplace, name, rebuild_strict, allow_input_downcast, profile, on_unused_input)\u001b[0m\n\u001b[1;32m    348\u001b[0m             \u001b[0mon_unused_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mon_unused_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m             \u001b[0mprofile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprofile\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 350\u001b[0;31m             \u001b[0moutput_keys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_keys\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    351\u001b[0m         )\n\u001b[1;32m    352\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/theano/compile/function/pfunc.py\u001b[0m in \u001b[0;36mpfunc\u001b[0;34m(params, outputs, mode, updates, givens, no_default_updates, accept_inplace, name, rebuild_strict, allow_input_downcast, profile, on_unused_input, output_keys)\u001b[0m\n\u001b[1;32m    425\u001b[0m     \u001b[0;31m# transform params into theano.compile.In objects.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m     inputs = [\n\u001b[0;32m--> 427\u001b[0;31m         \u001b[0m_pfunc_param_to_in\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_downcast\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mallow_input_downcast\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    428\u001b[0m     ]\n\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/theano/compile/function/pfunc.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    425\u001b[0m     \u001b[0;31m# transform params into theano.compile.In objects.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m     inputs = [\n\u001b[0;32m--> 427\u001b[0;31m         \u001b[0m_pfunc_param_to_in\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_downcast\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mallow_input_downcast\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    428\u001b[0m     ]\n\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/theano/compile/function/pfunc.py\u001b[0m in \u001b[0;36m_pfunc_param_to_in\u001b[0;34m(param, strict, allow_downcast)\u001b[0m\n\u001b[1;32m    541\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    542\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mparam\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 543\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Unknown parameter type: {type(param)}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    544\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    545\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: Unknown parameter type: <class 'theano.tensor.var.TensorVariable'>"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def load_dataset_Train_batch(AbnormalPath, NormalPath):\n",
        "    \n",
        "    print(\"Loading training batch\")\n",
        "\n",
        "    batchsize = 2  # Each batch contain 60 videos.\n",
        "    n_exp = batchsize // 2  # Number of abnormal and normal videos\n",
        "\n",
        "    Num_abnormal = 4  # Total number of abnormal videos in Training Dataset.\n",
        "    Num_Normal = 4  # Total number of Normal videos in Training Dataset.\n",
        "\n",
        "    # We assume the features of abnormal videos and normal videos are located in two different folders.\n",
        "    Abnor_list_iter = np.random.permutation(Num_abnormal)\n",
        "    Abnor_list_iter = Abnor_list_iter[Num_abnormal - n_exp:]  # Indexes for randomly selected Abnormal Videos\n",
        "    Norm_list_iter = np.random.permutation(Num_Normal)\n",
        "    Norm_list_iter = Norm_list_iter[Num_Normal - n_exp:]  # Indexes for randomly selected Normal Videos\n",
        "\n",
        "    AllVideos_Path = AbnormalPath\n",
        "\n",
        "    def listdir_nohidden(AllVideos_Path):  # To ignore hidden files\n",
        "        file_dir_extension = os.path.join(AllVideos_Path, '*.txt')\n",
        "        for f in glob.glob(file_dir_extension):\n",
        "            if not f.startswith('.'):\n",
        "                yield os.path.basename(f)\n",
        "\n",
        "    All_Videos = sorted(listdir_nohidden(AllVideos_Path))\n",
        "    #All_Videos = sorted(listdir_nohidden(AllVideos_Path))\n",
        "    All_Videos.sort()\n",
        "    AllFeatures = []  # To store C3D features of a batch\n",
        "    print(\"Loading Abnormal videos Features...\")\n",
        "\n",
        "    Video_count = -1\n",
        "    for iv in Abnor_list_iter:\n",
        "        Video_count = Video_count + 1\n",
        "        VideoPath = os.path.join(AllVideos_Path, All_Videos[iv])\n",
        "        f = open(VideoPath, \"r\")\n",
        "        words = f.read().split()\n",
        "        num_feat = len(words) // 4096\n",
        "        # Number of features per video to be loaded. In our case num_feat=32, as we divide the video into 32 segments. Note that\n",
        "        # we have already computed C3D features for the whole video and divide the video features into 32 segments. Please see Save_C3DFeatures_32Segments.m as well\n",
        "\n",
        "        count = -1\n",
        "        VideoFeatues = []\n",
        "        for feat in range(0, num_feat):\n",
        "            feat_row1 = np.float32(words[feat * 4096:feat * 4096 + 4096])\n",
        "            count = count + 1\n",
        "            if count == 0:\n",
        "                VideoFeatues = feat_row1\n",
        "            if count > 0:\n",
        "                VideoFeatues = np.vstack((VideoFeatues, feat_row1))\n",
        "\n",
        "        if Video_count == 0:\n",
        "            AllFeatures = VideoFeatues\n",
        "        if Video_count > 0:\n",
        "            AllFeatures = np.vstack((AllFeatures, VideoFeatues))\n",
        "        print(\" Abnormal Features  loaded\")\n",
        "\n",
        "    print(AllFeatures.shape)\n",
        "    print(AllFeatures[0])\n",
        "\n",
        "    print(\"Loading Normal videos...\")\n",
        "    AllVideos_Path = NormalPath\n",
        "\n",
        "    def listdir_nohidden(AllVideos_Path):  # To ignore hidden files\n",
        "        file_dir_extension = os.path.join(AllVideos_Path, '*.txt')\n",
        "        for f in glob.glob(file_dir_extension):\n",
        "            if not f.startswith('.'):\n",
        "                yield os.path.basename(f)\n",
        "\n",
        "    All_Videos = sorted(listdir_nohidden(AllVideos_Path))\n",
        "    All_Videos.sort()\n",
        "\n",
        "    for iv in Norm_list_iter:\n",
        "        VideoPath = os.path.join(AllVideos_Path, All_Videos[iv])\n",
        "        f = open(VideoPath, \"r\")\n",
        "        words = f.read().split()\n",
        "        feat_row1 = np.array([])\n",
        "        num_feat = len(\n",
        "            words) // 4096  # Number of features to be loaded. In our case num_feat=32, as we divide the video into 32 segments.\n",
        "\n",
        "        count = -1;\n",
        "        VideoFeatues = []\n",
        "        for feat in range(0, num_feat):\n",
        "\n",
        "            feat_row1 = np.float32(words[feat * 4096:feat * 4096 + 4096])\n",
        "            count = count + 1\n",
        "            if count == 0:\n",
        "                VideoFeatues = feat_row1\n",
        "            if count > 0:\n",
        "                VideoFeatues = np.vstack((VideoFeatues, feat_row1))\n",
        "            feat_row1 = []\n",
        "        AllFeatures = np.vstack((AllFeatures, VideoFeatues))\n",
        "\n",
        "    print(\"Features  loaded\")\n",
        "\n",
        "    AllLabels = np.zeros(32 * batchsize, dtype='uint8')\n",
        "    th_loop1 = n_exp * 32\n",
        "    th_loop2 = n_exp * 32 - 1\n",
        "\n",
        "    for iv in range(0, 32 * batchsize):\n",
        "        if iv < th_loop1:\n",
        "            AllLabels[iv] = int(\n",
        "                0)  # All instances of abnormal videos are labeled 0.  This will be used in custom_objective to keep track of normal and abnormal videos indexes.\n",
        "        if iv > th_loop2:\n",
        "            AllLabels[iv] = int(\n",
        "                1)  # All instances of Normal videos are labeled 1. This will be used in custom_objective to keep track of normal and abnormal videos indexes.\n",
        "    # print(\"ALLabels  loaded\")\n",
        "\n",
        "    return AllFeatures, AllLabels"
      ],
      "metadata": {
        "id": "pgU3WBi0zqH_"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "EueEYmGY2aEP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}